{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Overview\n",
    "\n",
    "Your task will be to predict the next set of characters using the previous characters. \n",
    "- Although this task sounds simple, it is pretty useful.\n",
    "- You will start by converting a line of text into a tensor\n",
    "- Then you will create a generator to feed data into the model\n",
    "- You will train a neural network in order to predict the new set of characters of defined length. \n",
    "- You will use embeddings for each character and feed them as inputs to your model. \n",
    "    - Many natural language tasks rely on using embeddings for predictions. \n",
    "- Your model will convert each character to its embedding, run the embeddings through a Gated Recurrent Unit `GRU`, and run it through a linear layer to predict the next set of characters.\n",
    "\n",
    "<img src = \"images/model.png\" style=\"width:600px;height:150px;\"/>\n",
    "\n",
    "The figure above gives you a summary of what you are about to implement. \n",
    "- You will get the embeddings;\n",
    "- Stack the embeddings on top of each other;\n",
    "- Run them through two layers with a relu activation in the middle;\n",
    "- Finally, you will compute the softmax. \n",
    "\n",
    "To predict the next character:\n",
    "- Use the softmax output and identify the word with the highest probability.\n",
    "- The word with the highest probability is the prediction for the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-09 15:09:03.853505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mbarbari/.pyenv/versions/3.10.5/envs/course3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import trax\n",
    "import trax.fastmath.numpy as np\n",
    "import pickle\n",
    "import random as rnd\n",
    "from trax import fastmath\n",
    "from trax import layers as tl\n",
    "\n",
    "import w2_unittest\n",
    "\n",
    "rnd.seed(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"data/\"\n",
    "filename = \"shakespeare_data.txt\"\n",
    "lines = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open(os.path.join(dirname, filename)) as files:\n",
    "    for line in files:\n",
    "        pure_line = line.strip()\n",
    "\n",
    "        if pure_line:\n",
    "            lines.append(pure_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines 125097\n",
      "Sample line at position 0 A LOVER'S COMPLAINT\n",
      "Sampel line at position 999 With this night's revels and expire the term\n"
     ]
    }
   ],
   "source": [
    "n_lines = len(lines)\n",
    "print(f\"Number of lines {n_lines}\")\n",
    "print(f\"Sample line at position 0 {lines[0]}\")\n",
    "print(f\"Sampel line at position 999 {lines[999]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 125097\n",
      "Sample line at position 0 a lover's complaint\n",
      "Sample line at position 999 with this night's revels and expire the term\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(lines):\n",
    "    lines[i] = line.lower()\n",
    "\n",
    "\n",
    "print(f\"Number of lines: {n_lines}\")\n",
    "print(f\"Sample line at position 0 {lines[0]}\")\n",
    "print(f\"Sample line at position 999 {lines[999]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines for training: 124097\n",
      "Number of lines for validation: 1000\n"
     ]
    }
   ],
   "source": [
    "eval_lines = lines[-1000:]\n",
    "lines = lines[:-1000]\n",
    "\n",
    "print(f\"Number of lines for training: {len(lines)}\")\n",
    "print(f\"Number of lines for validation: {len(eval_lines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a line to a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_tensor(line, EOS_int=1):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for c in line:\n",
    "        char = ord(c)\n",
    "        tensor.append(char)\n",
    "    \n",
    "    tensor.append(EOS_int)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97, 98, 99, 32, 120, 121, 122, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_to_tensor(\"abc xyz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
